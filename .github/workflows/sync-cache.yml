on:
  schedule:
    - cron: '0 */6 * * *'
  workflow_dispatch:

jobs:
  sync-cache:
    name: Auto-sync cache from Google Drive
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install rclone
        run: sudo apt-get update && sudo apt-get install -y rclone

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install Python dependencies
        run: pip install pandas pyarrow plotly streamlit

      - name: Load rclone config
        env:
          RCLONE_CONFIG_CONTENT: ${{ secrets.RCLONE_CONFIG }}
        run: |
          mkdir -p ~/.config/rclone
          echo "$RCLONE_CONFIG_CONTENT" > ~/.config/rclone/rclone.conf

      - name: Generate fresh cache directly from Google Drive
        env:
          PARENT_RUNS_FOLDER: "ZEF_Container_Dashboard:/Container Plant Dashboard/Parquet_Exports"
        run: |
          python Hours_V31.py  # or: python generate_cache.py

      - name: Upload new cache back to Drive
        run: |
          rclone sync cache "ZEF_Container_Dashboard:/Container Plant Dashboard/Parquet_Exports/cache" --create-empty-src-dirs --progress

      - name: Commit and push updated cache to GitHub
        run: |
          git config user.name "Auto-sync Bot"
          git config user.email "bot@noreply.github.com"
          mkdir -p cache
          touch cache/.gitkeep 2>/dev/null || true
          git add cache/
          if ! git diff --staged --quiet; then
            git commit -m "Auto-update cache $(date +'%Y-%m-%d %H:%M')"
            git push
          else
            echo "No cache changes"
          fi